# Proposed by Mihai:

Learning Language Games through Interaction
http://arxiv.org/pdf/1606.02447.pdf

## Matching Networks for One Shot Learning
http://arxiv.org/pdf/1606.04080v1.pdf

## Knowledge Base Unification via Sense Embeddings and Disambiguation
https://www.semanticscholar.org/paper/Knowledge-Base-Unification-via-Sense-Embeddings-Bovi-Anke/874b8e70bc560315c21cd2692037f079e623347d/pdf

## Globally Normalized Transition-based Neural Networks
http://arxiv.org/pdf/1603.06042v1.pdf

## Question Answering with Subgraph Embeddings
http://arxiv.org/pdf/1406.3676v3.pdf

## Building Machines That Learn and Think Like People
http://arxiv.org/abs/1604.00289

## Visualizing and Understanding Neural Models in NLP
http://arxiv.org/abs/1506.01066

## XGBoost: A Scalable Tree Boosting System
http://arxiv.org/abs/1603.02754

## Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations
http://arxiv.org/abs/1603.04351

## Representing Text for Joint Embedding of Text and Knowledge Bases
http://research.microsoft.com/pubs/254916/emnlp2015kgtext.pdf

## Harnessing Deep Neural Networks with Logic Rules
http://arxiv.org/abs/1603.06318

## Probabilistic Reasoning via Deep Learning: Neural Association Models
http://arxiv.org/abs/1603.07704

## Symbolic Knowledge Extraction using Lukasiewicz Logics
https://arxiv.org/abs/1604.03099#

# Proposed by Michael:

## Tutorial on Reinforcement Learning
https://www.nervanasys.com/demystifying-deep-reinforcement-learning/
### Playing Atari with Deep Reinforcement Learning
http://arxiv.org/pdf/1312.5602v1.pdf
### Deep Reinforcement Learning for Dialogue Generation
https://arxiv.org/pdf/1606.01541v3.pdf

## A Persona-based Neural Conversation Model
http://arxiv.org/pdf/1603.06155.pdf

##Neural Machine Translation By Jointly Learning to Align and Translate
The seminal paper that introduces an "attention mechanism" to sequence-to-sequence models
http://arxiv.org/pdf/1409.0473.pdf

##Learning to Tranduce with Unbounded Memory
Comes up with the idea of "neural stacks"
http://arxiv.org/pdf/1506.02516.pdf

##Sentence Level Recurrent Topic Model: Letting Topics Speak for Themselves
https://arxiv.org/pdf/1604.02038v1

##“Why Should I Trust You?” Explaining the Predictions of Any Classifier
http://arxiv.org/pdf/1602.04938v1.pdf

##Easy-First Dependency Parsing with Hierarchical Tree LSTMs
http://arxiv.org/pdf/1603.00375v1.pdf

##Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks
http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf

##BLACKOUT: Speeding Up Recurrent Neural Network Language Models With Very Large Vocabularies
http://arxiv.org/pdf/1511.06909v7.pdf

##Deep Networks with Stochastic Depth
Summarized in this blog post: http://deliprao.com/archives/134
http://arxiv.org/abs/1603.09382v1

# Proposed by Marco:

## Automatic Extraction of Causal Relations from Natural Language Texts: A Comprehensive Survey
https://arxiv.org/abs/1605.07895

## Toward Future Scenario Generation: Extracting Event Causality Exploiting Semantic Relation, Context, and Association Features
http://acl2014.org/acl2014/P14-1/pdf/P14-1093.pdf

## Concept Grounding to Multiple Knowledge Bases via Indirect Supervision
https://aclweb.org/anthology/Q/Q16/Q16-1011.pdf

## Joint Extraction of Events and Entities within a Document Context
http://www.cs.cmu.edu/~bishan/papers/joint_event_naacl16.pdf

## Bidirectional RNN for Medical Event Detection in Electronic Health Records
http://aclweb.org/anthology/N/N16/N16-1056.pdf

## Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning
http://arxiv.org/pdf/1603.07954v1.pdf

## A Fast Unified Model for Parsing and Sentence Understanding
http://arxiv.org/pdf/1603.06021.pdf

## Learning a Compositional Semantics for Freebase with an Open Predicate Vocabulary
https://aclweb.org/anthology/Q/Q15/Q15-1019.pdf

## Long Short-Term Memory-Networks for Machine Reading
https://arxiv.org/pdf/1601.06733v5

## End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures
http://arxiv.org/pdf/1601.00770v2.pdf

## Augur: Mining Human Behaviors from Fiction to Power Interactive Systems
http://hci.stanford.edu/publications/augur-chi-2016.pdf

## What we write about when we write about causality: Features of causal statements across large-scale social discourse
https://arxiv.org/abs/1604.05781

## Learning to Generate Posters of Scientific Papers
http://arxiv.org/pdf/1604.01219v1.pdf

# Proposed by Dane:

## Word Sense Disambiguation with Neural Language Models
http://arxiv.org/pdf/1603.07012.pdf

## Explaining Predictions of Non-Linear Classifiers in NLP
https://arxiv.org/pdf/1606.07298v1.pdf

## On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation
http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140

