# Candidate papers for Fall 2020

|    | Proposer    | Paper |
|:---|:------------|:------|
| 1  | Steven      |[Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks](https://www.aclweb.org/anthology/2020.acl-main.740) |
| 2  | Steven      |[Named Entity Recognition as Dependency Parsing](https://www.aclweb.org/anthology/2020.acl-main.577)|
| 3  | Steven      |[Tabula nearly Rasa: Probing the linguistic knowledge of character-level neural language models trained on unsegmented text](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00283)|
| 4  | Masha       |[How much progress have we made on RST discourse parsing? A replication study of recent results on the RST-DT](https://www.aclweb.org/anthology/D17-1136.pdf) The gist: Inconsistency among evaluation metrics leads to inaccurate picture of progress made on the task. |
| 5 | Mihai | [Dekang Lin's DIRT paper](https://dl.acm.org/doi/abs/10.1145/502512.502559?casa_token=0kvKZFkGrJQAAAAA:O62mO2TMuhubif_GpGDlUHt6qzRJtOc-PL5AJW_ggSwo5B_HK-qHl5-N5mo4ow_suuXLxmILr5FB) |
| 6 | Hoang | [Neural CRF Model for Sentence Alignment in Text Simplification](https://www.aclweb.org/anthology/2020.acl-main.709/)
| 7 | Vikas | [An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction](https://arxiv.org/abs/2005.00652)
| 8 | Yiyun | [Probing Linguistic Systematicity](https://www.aclweb.org/anthology/2020.acl-main.177/)
| 9 | Yiyun | [A Graph-based Coarse-to-fine Method for Unsupervised Bilingual Lexicon Induction](https://www.aclweb.org/anthology/2020.acl-main.318/)
| 10 | Andrew | [Minimally Supervised Number Normalization](https://www.aclweb.org/anthology/Q16-1036.pdf)
| 11| Sina | [Large-Scale Adversarial Training for Vision-and-Language Representation Learning](https://arxiv.org/pdf/2006.06195.pdf)
| 12| Zheng | [Lexically Constrained Neural Machine Translation with Levenshtein Transformer](https://www.aclweb.org/anthology/2020.acl-main.325.pdf)
| 13| Zheng | [Beyond Accuracy: Behavioral Testing of NLP Models with CheckList](https://www.aclweb.org/anthology/2020.acl-main.442.pdf)
| 14| Zheng | [Evaluating Explanation Methods for Neural Machine Translation](https://www.aclweb.org/anthology/2020.acl-main.35.pdf)
| 15 | Jiacheng    |[Theoretical Limitations of Self-Attention in Neural Sequence Models](https://www.aclweb.org/anthology/2020.tacl-1.11.pdf). Transformers sucks, proved mathematically
| 16| mithun | [“Who said it, and Why?" Work from Dan Roths team on Provenance for Natural Language Claims](https://www.aclweb.org/anthology/2020.acl-main.406.pdf)
| 17 | mithun    |[Zero-shot Text Classification via Reinforced Self-training](https://www.aclweb.org/anthology/2020.acl-main.272.pdf)
| 18 | Peter L | [Generalization through Memorization: Nearest Neighbor Language Models](https://openreview.net/forum?id=HklBjCEKvH)

